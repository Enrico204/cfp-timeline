name: Update scraping

on:
  schedule:
    # 7am UTC = 9am CET, 3am EDT, 0am PDT âˆ’ should be light hours globally for WikiCFP.
    - cron: '0 7 * * *'
  workflow_dispatch:


jobs:
  update:
    name: Update scraping
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v1

    - name: Install dependencies
      run: |
        python3 -m pip install -r ./requirements.txt
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git config --global user.name "github-actions[bot]"

    - name: Do the scraping
      run: |
        # Takes ~3h50 with 2.5s delay, limit for github actions is 6h.
        # wikicfp recommends 5s delay but with 4s the process already would last est. 6h09.
        # Alternately 3s (est. 4h37) or 3.5s (est. 5h23)?
        (( $RANDOM < 32768 / 30 )) && python3 ./updater.py --quiet --no-cache --delay 2.5 core
        (( $RANDOM < 32768 / 30 )) && python3 ./updater.py --quiet --no-cache ggs
        python3 ./updater.py --quiet --no-cache --delay 2.5 cfps

    - name: Push to GitHub
      run: |
        git add core.csv cfp.json parsing_errors.txt
        git commit -m "Update scraping $(date --rfc-3339=date)"
        git push https://${TOKEN}@github.com/${GITHUB_REPOSITORY} HEAD:master
      env:
        TOKEN: ${{ secrets.CORE_CFP_PUSHER }}
